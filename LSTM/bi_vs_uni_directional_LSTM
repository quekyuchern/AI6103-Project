{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.datasets import fetch_20newsgroups\nimport nltk\nnltk.download('wordnet')\n!unzip -o /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n\ndf = pd.DataFrame({\n    'Text': newsgroups.data,\n    'Category': newsgroups.target\n})\ndf['Category Name'] = df['Category'].apply(lambda x: newsgroups.target_names[x])\ndf\n\n# Lowercasing\ndf['Text'] = df['Text'].str.lower()\n\n# Remove Punctuation and special characters\ndf['Text'] = df['Text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n\n# Tokenization\ndf['Tokens'] = df['Text'].apply(word_tokenize)\n\n# Removing Stopwords\nstop_words = set(stopwords.words('english'))\ndf['Tokens'] = df['Tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n\n# Lemmatization\nlemmatizer = WordNetLemmatizer()\ndf['Tokens'] = df['Tokens'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df['Text'])\n\n# Convert texts to sequences\nsequences = tokenizer.texts_to_sequences(df['Text'])\nmax_seq_length = max(len(seq) for seq in sequences)\npadded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n\nfrom tensorflow.keras.utils import to_categorical\ny = to_categorical(df['Category'])\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n\n# Model with Unidirectional LSTM\nmodel_uni = Sequential([\n    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128, input_length=max_seq_length),\n    LSTM(128),\n    Dense(len(newsgroups.target_names), activation='softmax')\n])\n\n# Model with Bidirectional LSTM\nmodel_bi = Sequential([\n    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128, input_length=max_seq_length),\n    Bidirectional(LSTM(128)),\n    Dense(len(newsgroups.target_names), activation='softmax')\n])\n\nx_train, x_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n\n# Compile both models\nfor model in [model_uni, model_bi]:\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train Unidirectional LSTM model\nhistory_uni = model_uni.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)\n\n# Train Bidirectional LSTM model\nhistory_bi = model_bi.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:29:08.367913Z","iopub.execute_input":"2024-10-30T08:29:08.368400Z","iopub.status.idle":"2024-10-30T09:37:20.740859Z","shell.execute_reply.started":"2024-10-30T08:29:08.368350Z","shell.execute_reply":"2024-10-30T09:37:20.739717Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract and store the training history\ntrain_uni_loss = history_uni.history['loss']\nval_uni_loss = history_uni.history['val_loss']\ntrain_uni_accuracy = history_uni.history['accuracy']\nval_uni_accuracy = history_uni.history['val_accuracy']\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:37:20.743498Z","iopub.execute_input":"2024-10-30T09:37:20.743851Z","iopub.status.idle":"2024-10-30T09:37:20.749063Z","shell.execute_reply.started":"2024-10-30T09:37:20.743814Z","shell.execute_reply":"2024-10-30T09:37:20.747989Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract and store the training history\ntrain_bi_loss = history_bi.history['loss']\nval_bi_loss = history_bi.history['val_loss']\ntrain_bi_accuracy = history_bi.history['accuracy']\nval_bi_accuracy = history_bi.history['val_accuracy']\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:37:20.750263Z","iopub.execute_input":"2024-10-30T09:37:20.750946Z","iopub.status.idle":"2024-10-30T09:37:20.760817Z","shell.execute_reply.started":"2024-10-30T09:37:20.750903Z","shell.execute_reply":"2024-10-30T09:37:20.759968Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(train_uni_accuracy, label='Training Uni Accuracy')\nplt.plot(val_uni_accuracy, label='Validation Uni Accuracy')\nplt.plot(train_bi_accuracy, label='Training Bi Accuracy')\nplt.plot(val_bi_accuracy, label='Validation Bi Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:37:20.762011Z","iopub.execute_input":"2024-10-30T09:37:20.762366Z","iopub.status.idle":"2024-10-30T09:37:21.109876Z","shell.execute_reply.started":"2024-10-30T09:37:20.762297Z","shell.execute_reply":"2024-10-30T09:37:21.109053Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_uni_loss, test_uni_accuracy = model_uni.evaluate(x_test, y_test)\nprint(f\"Test Uni Loss: {test_uni_loss}\")\nprint(f\"Test Uni Accuracy: {test_uni_accuracy}\")\n\ntest_bi_loss, test_bi_accuracy = model_bi.evaluate(x_test, y_test)\nprint(f\"Test Bi Loss: {test_bi_loss}\")\nprint(f\"Test Bi Accuracy: {test_bi_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:56:38.905727Z","iopub.execute_input":"2024-10-30T09:56:38.906401Z","iopub.status.idle":"2024-10-30T09:58:32.497532Z","shell.execute_reply.started":"2024-10-30T09:56:38.906360Z","shell.execute_reply":"2024-10-30T09:58:32.496546Z"},"trusted":true},"outputs":[],"execution_count":null}]}