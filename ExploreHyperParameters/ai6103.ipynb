{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9692536,"sourceType":"datasetVersion","datasetId":5925846}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install googletrans==4.0.0-rc1\nimport joblib\nimport asyncio\nimport random\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport requests\nimport os\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom sklearn.datasets import fetch_20newsgroups\nfrom transformers import BertTokenizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import regularizers  # Add this import\nfrom nltk.corpus import wordnet\nfrom googletrans import Translator\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom functools import lru_cache\n\nprint(\"Is GPU available:\", tf.test.is_gpu_available())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:15:54.581247Z","iopub.execute_input":"2024-11-14T12:15:54.581613Z","iopub.status.idle":"2024-11-14T12:16:43.136744Z","shell.execute_reply.started":"2024-11-14T12:15:54.581571Z","shell.execute_reply":"2024-11-14T12:16:43.135789Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Load data set**","metadata":{}},{"cell_type":"code","source":"# x_train, y_train, x_test, y_test = joblib.load('/kaggle/input/ai6103-bc/bert_train_test_data.pkl')  #use embedded data\n\n# Split the training set further into a new training set and a validation set\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\nx = newsgroups.data  # Text data\ny = newsgroups.target  # Labels\n\n# Split the data into training and testing sets (80% train, 20% test)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\n# Further split the training data into training and validation sets (80% train, 20% validation)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n\n# Print sizes of the datasets\nprint(f\"Size of training set: {len(x_train)} samples\")\nprint(f\"Size of validation set: {len(x_val)} samples\")\nprint(f\"Size of testing set: {len(x_test)} samples\")\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(x_train)\n\n# Define vocab_size as the total number of unique words\nvocab_size = len(tokenizer.word_index) + 1  # +1 for padding or unknown token\n\nprint(\"Vocabulary size:\", vocab_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:16:43.138646Z","iopub.execute_input":"2024-11-14T12:16:43.140433Z","iopub.status.idle":"2024-11-14T12:16:57.817359Z","shell.execute_reply.started":"2024-11-14T12:16:43.140396Z","shell.execute_reply":"2024-11-14T12:16:57.816375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Build a base model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, BatchNormalization\n\n# Set up early stopping\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',     # Monitor the validation loss\n    patience=20,             # Number of epochs to wait for improvement\n    restore_best_weights=True  # Restore the weights of the best epoch if no improvement\n)\n\nmax_sequence_length, embedding_dim = 128, 768\n\n##model without augmentation\n# def create_model(dropout_rate=0.0, use_batch_norm=False, use_regularization=False, l1=0.01, l2=0.01):\n#     model = Sequential()\n    \n#     if use_regularization:\n#         model.add(LSTM(128, \n#                        input_shape=(max_sequence_length, embedding_dim), \n#                        return_sequences=False,\n#                        kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))  # Apply L1 and L2 regularization\n#     else:\n#         model.add(LSTM(128, input_shape=(max_sequence_length, embedding_dim), return_sequences=False))\n\n#     if use_batch_norm:\n#         model.add(BatchNormalization())  # Batch norm after LSTM\n   \n#     # Dropout after LSTM\n#     if dropout_rate > 0.0:\n#         model.add(Dropout(dropout_rate))\n        \n#     if use_regularization:\n#         model.add(Dense(64, kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))  # Apply Elastic Net regularization\n#     else:\n#         model.add(Dense(64))  # Fully connected layer\n\n#     if use_batch_norm:\n#         model.add(BatchNormalization())  # Batch norm after LSTM\n\n#     # Dropout after first Dense layer\n#     if dropout_rate > 0.0:\n#         model.add(Dropout(dropout_rate))\n        \n#     if use_regularization:\n#         model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))  # Apply Elastic Net regularization\n#     else:\n#         model.add(Dense(64, activation='relu'))  # ReLU function\n    \n#     # Dropout after second Dense layer\n#     if dropout_rate > 0.0:\n#         model.add(Dropout(dropout_rate))\n        \n#     num_classes = len(np.unique(y_train))\n#     model.add(Dense(num_classes, activation='softmax'))\n\n#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n#     return model\n\n\ndef create_model(dropout_rate=0.0, use_batch_norm=False, use_regularization=False, l1=0.01, l2=0.01):\n    input_ids = Input(shape=(max_sequence_length,), name='input_ids')  # Corrected shape\n    attention_mask = Input(shape=(max_sequence_length,), name='attention_mask')  # Only if you're using attention_mask\n\n     # Add an embedding layer\n    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)(input_ids)\n\n    x = LSTM(128, return_sequences=False, name='lstm_layer')(x)\n\n    if use_batch_norm:\n        x = BatchNormalization()(x)  # Batch norm after LSTM\n    \n    if dropout_rate > 0.0:\n        x = Dropout(dropout_rate)(x)\n\n    if use_regularization:\n        x = Dense(64, kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2))(x)  # Regularization\n    else:\n        x = Dense(64)(x)\n\n    if use_batch_norm:\n        x = BatchNormalization()(x)  # Batch norm after Dense layer\n    \n    if dropout_rate > 0.0:\n        x = Dropout(dropout_rate)(x)\n    \n    x = Dense(64, activation='relu')(x)\n    \n    if dropout_rate > 0.0:\n        x = Dropout(dropout_rate)(x)\n    \n    num_classes = len(np.unique(y_train))  # Ensure y_train is defined\n    output = Dense(num_classes, activation='softmax')(x)\n\n    model = Model(inputs=[input_ids, attention_mask], outputs=output)\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:16:57.818690Z","iopub.execute_input":"2024-11-14T12:16:57.819005Z","iopub.status.idle":"2024-11-14T12:16:57.831693Z","shell.execute_reply.started":"2024-11-14T12:16:57.818971Z","shell.execute_reply":"2024-11-14T12:16:57.830793Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Augment Data**","metadata":{}},{"cell_type":"code","source":"import nest_asyncio\n# Apply the workaround for nested event loops\nnest_asyncio.apply()\n\n# Function to get synonyms for a given word\ndef get_synonyms(word):\n    response = requests.get(f'https://api.datamuse.com/words?rel_syn={word}')\n    return [item['word'] for item in response.json()]\n\n# Initialize the translator\ntranslator = Translator()\n\nasync def translate_sentence(sentence, srcl, destl):\n    try:\n        result = translator.translate(sentence, src=srcl, dest=destl)\n        # Check if result is valid and contains text\n        if result and result.text:\n            return result.text\n        else:\n            return sentence  # Fallback to the original sentence\n    except Exception as e:\n        return sentence  # Fallback in case of an error\n        \nasync def back_translate_async(sentences, language):\n    print(len(sentences))\n    translated_texts = []\n    tasks = [translate_sentence(sentence, 'en', language) for sentence in sentences]\n    \n    translations = await asyncio.gather(*tasks)\n    \n    # Translate back to English\n    back_tasks = [translate_sentence(t, language, 'en') for t in translations]\n    back_translations = await asyncio.gather(*back_tasks)\n    \n    return back_translations\n    \ndef random_word_insertion_deletion(sentence):\n    words = sentence.split()\n    # Ensure that we have words to work with\n    if len(words) == 0:\n        return sentence  # Return the original sentence if it is empty\n  \n    if random.random() > 0.5 and len(words) > 1:\n        words.pop(random.randint(0, len(words) - 1))  # Word deletion\n    else:\n        random_word = random.choice(words)\n        synonyms = get_synonyms(random_word)\n        if synonyms:\n            new_word = random.choice(synonyms)\n            words.insert(random.randint(0, len(words)), new_word)\n    return ' '.join(words)\n    \n\n# Asynchronous function to augment text data with back translation and insertion/deletion\nasync def augment_text_data(x_train, y_train, language='en', \n                            back_translate_ratio=0.5, insertion_deletion_ratio=0.5):\n    augmented_x_train = []\n    augmented_y_train = []\n    \n    # Calculate the number of samples for each augmentation\n    num_back_translate = int(len(x_train) * back_translate_ratio)\n    num_insertion_deletion =  int(len(x_train) * insertion_deletion_ratio)\n    \n    # Sample indices for back translation\n    back_translate_indices = random.sample(range(len(x_train)), num_back_translate)\n    back_translate_sentences = [x_train[i] for i in back_translate_indices]\n    \n    # 1. Perform back translation asynchronously\n    if back_translate_ratio > 0:\n        print('Starting async back translation...')\n        back_translated_sentences = await back_translate_async(back_translate_sentences, language)\n        print('Back translation completed.')\n        \n        # Add back translated sentences to augmented data with corresponding labels\n        augmented_x_train.extend(back_translated_sentences)\n        augmented_y_train.extend([y_train[i] for i in back_translate_indices])\n\n    # 2. Perform random word insertion/deletion for remaining sentences\n    remaining_indices = [i for i in range(len(x_train)) if i not in back_translate_indices]\n    \n    print('Starting random word insertion deletion...')\n    modified_sentences = [\n        random_word_insertion_deletion(x_train[i]) if random.random() < insertion_deletion_ratio else x_train[i]\n        for i in remaining_indices\n    ]\n    print('Random word insertion deletion completed.')\n\n    \n    # Add modified sentences to the augmented data with original labels\n    augmented_x_train.extend(modified_sentences)\n    augmented_y_train.extend([y_train[i] for i in remaining_indices])\n\n    return augmented_x_train, augmented_y_train\n\n\n# Run the async function within the event loop# Run the augment_data function asynchronously within the event loop\naugmented_x_train, augmented_y_train = await augment_text_data(x_train, y_train, 'fr')\n\nx_train_augmented = list(x_train) + augmented_x_train\ny_train_augmented = list(y_train) + augmented_y_train\n\n\n# Final check for equality\nprint(f\"Final X Training samples: {len(x_train_augmented)}\")\nprint(f\"Final Y Training samples: {len(y_train_augmented)}\")\n\nprint(f'Augmented X Training samples: {len(x_train_augmented)}')\nprint(f'Augmented Y Training samples: {len(y_train_augmented)}')\n\n# Step 3: Tokenize the text data using BERT\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Tokenizing combined training data\ntokens = tokenizer(x_train_augmented, padding=True, truncation=True, return_tensors='pt', max_length=128)\n# Tokenizing validation and test data\ntokens_val = tokenizer(x_val, padding=True, truncation=True, return_tensors='pt', max_length=128)\ntokens_test = tokenizer(x_test, padding=True, truncation=True, return_tensors='pt', max_length=128)\n\n# Extracting input IDs and attention masks\ninput_ids = tokens['input_ids'].numpy()\nattention_mask = tokens['attention_mask'].numpy()\n\ninput_ids_val = tokens_val['input_ids'].numpy()\nattention_mask_val = tokens_val['attention_mask'].numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T12:16:57.833977Z","iopub.execute_input":"2024-11-14T12:16:57.834306Z","iopub.status.idle":"2024-11-14T15:41:23.861109Z","shell.execute_reply.started":"2024-11-14T12:16:57.834272Z","shell.execute_reply":"2024-11-14T15:41:23.860278Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Train models**","metadata":{}},{"cell_type":"code","source":"\ndef train_and_evaluate(dropout_rate, y_train_augmented, use_batch_norm=False, use_regularization=False, l1=0.01, l2=0.01):\n    model = create_model(dropout_rate, use_batch_norm, use_regularization, l1, l2)\n    \n    # Convert y_train_augmented to numpy array if it's not already\n    y_train_augmented = np.array(y_train_augmented)\n    \n    # Debug output to check shapes\n    print(f'y_train_augmented shape: {y_train_augmented.shape}')  \n    print(f'Input IDs shape: {input_ids.shape}')                  \n    print(f'Attention Mask shape: {attention_mask.shape}')        \n    print(f'Validation Input IDs shape: {input_ids_val.shape}')   \n    print(f'Validation Attention Mask shape: {attention_mask_val.shape}')  \n    print(f'Validation labels shape: {y_val.shape}')              \n\n    history = model.fit(\n        x={'input_ids': input_ids, 'attention_mask': attention_mask},\n        y=y_train_augmented,\n        epochs=150,\n        batch_size=32,\n        validation_data=({'input_ids': input_ids_val, 'attention_mask': attention_mask_val}, y_val),\n        callbacks=[early_stopping],\n        verbose=1\n    )\n    return model, history\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:41:23.862249Z","iopub.execute_input":"2024-11-14T15:41:23.862533Z","iopub.status.idle":"2024-11-14T15:41:23.870001Z","shell.execute_reply.started":"2024-11-14T15:41:23.862499Z","shell.execute_reply":"2024-11-14T15:41:23.869055Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Explore parameters**","metadata":{}},{"cell_type":"code","source":"# # no batch norm\n# model0, history0 = train_and_evaluate(0, False, False, False)\n# #with batch norm\n# model1, history1 = train_and_evaluate(0, True, False, False)\n\n# #with regularization - elastic net\n# l1_values = [0, 1e-4, 1e-3, 1e-2]  # List of L1 values to test\n# l2_values = [0, 1e-4, 1e-3, 1e-2]  # List of L2 values to test\n    \n# results = []  # Store results for each combination\n    \n# for l1 in l1_values:\n#     for l2 in l2_values:\n#         print(f\"Training with L1: {l1}, L2: {l2}\")\n#         model, history = train_and_evaluate(\n#                 0.0,b\n#                 use_batch_norm=False,\n#                 use_regularization=True,  # Enable regularization\n#                 use_augmentation=False,\n#                 l1=l1,\n#                 l2=l2\n#             )\n            \n#         # Evaluate the model on validation set\n#         test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n#         results.append((l1, l2, test_loss, test_accuracy, history))\n#         print(f\"L1: {l1}, L2: {l2}, Testing Loss: {test_loss}, Testing Accuracy: {test_accuracy}\")\n\n#with dropout rate\n# results = []  # Store results for each combination\n# dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.5]\n# for dropout_rate in dropout_rates:\n#     print(f\"Training with Dropout Rate: {dropout_rate}\")\n#     model, history = train_and_evaluate(\n#         dropout_rate=dropout_rate,\n#         use_batch_norm=True,\n#         use_regularization=False,  # Enable regularization if desired\n#         use_augmentation=False,\n#         l1=0.0,   # You can fix L1 and L2 values here, e.g., to the best found previously\n#         l2=0.0 # Adjust as necessary\n#     )\n    \n#     test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n#     results.append((dropout_rate, test_loss, test_accuracy, history))\n#     print(f\"Dropout Rate: {dropout_rate}, Testing Loss: {test_loss}, Testing Accuracy: {test_accuracy}\")\n\n# # Convert results to a structured format for easy plotting\n# dropout_rates = [result[0] for result in results]\n# test_losses = [result[1] for result in results]\n# test_accuracies = [result[2] for result in results]\n\n \nmodel, history = train_and_evaluate(\n        dropout_rate=0.3,\n        y_train_augmented=y_train_augmented, \n        use_batch_norm=True,\n        use_regularization=False,  # Enable regularization if desired\n        l1=0,   \n        l2=0\n)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:41:23.871160Z","iopub.execute_input":"2024-11-14T15:41:23.871469Z","iopub.status.idle":"2024-11-14T16:04:45.312559Z","shell.execute_reply.started":"2024-11-14T15:41:23.871439Z","shell.execute_reply":"2024-11-14T16:04:45.311607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# # # Plotting the results\n# plt.figure(figsize=(18, 12))\n\n# # Plotting Training Loss\n# plt.subplot(2, 2, 1)\n# for result in results:\n#     _, _, _, _, history = result\n#     plt.plot(history.history['loss'], label=f'Train Loss (L1: {result[0]}, L2: {result[1]})')\n        \n# plt.title('Training Loss for Different L1 and L2 Values')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.grid(True)\n\n#  # Plotting Validation Loss\n# plt.subplot(2, 2, 2)\n# for result in results:\n#     _, _, _, _, history = result\n#     plt.plot(history.history['val_loss'], label=f'Val Loss (L1: {result[0]}, L2: {result[1]})')\n        \n# plt.title('Validation Loss for Different L1 and L2 Values')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.grid(True)\n\n# # Plotting Training Accuracy\n# plt.subplot(2, 2, 3)\n# for result in results:\n#     _, _, _, _, history = result\n#     plt.plot(history.history['accuracy'], label=f'Train Accuracy (L1: {result[0]}, L2: {result[1]})')\n        \n# plt.title('Training Accuracy for Different L1 and L2 Values')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy')\n# plt.legend()\n# plt.grid(True)\n\n# # Plotting Validation Accuracy\n# plt.subplot(2, 2, 4)\n# for result in results:\n#     _, _, _, _, history = result\n#     plt.plot(history.history['val_accuracy'], label=f'Val Accuracy (L1: {result[0]}, L2: {result[1]})')\n        \n# plt.title('Validation Accuracy for Different L1 and L2 Values')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy')\n# plt.legend()\n# plt.grid(True)\n\n# # Overall layout adjustments\n# plt.tight_layout()\n# plt.show()\n# Prepare to plot the metrics\n# plt.figure(figsize=(18, 12))\n\n# # Plotting training loss\n# plt.subplot(2, 2, 1)\n# for result in results:\n#     history = result[3]\n#     plt.plot(history.history['loss'], label=f'Dropout {result[0]}')\n# plt.title('Training Loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.grid()\n\n# # Plotting training accuracy\n# plt.subplot(2, 2, 2)\n# for result in results:\n#     history = result[3]\n#     plt.plot(history.history['accuracy'], label=f'Dropout {result[0]}')\n# plt.title('Training Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy')\n# plt.legend()\n# plt.grid()\n\n# # Plotting validation loss\n# plt.subplot(2, 2, 3)\n# for result in results:\n#     history = result[3]\n#     plt.plot(history.history['val_loss'], label=f'Dropout {result[0]}')\n# plt.title('Validation Loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.grid()\n\n# # Plotting validation accuracy\n# plt.subplot(2, 2, 4)\n# for result in results:\n#     history = result[3]\n#     plt.plot(history.history['val_accuracy'], label=f'Dropout {result[0]}')\n# plt.title('Validation Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy')\n# plt.legend()\n# plt.grid()\n\n# # Show the plots\n# plt.tight_layout()\n# plt.show()\n\n# Extract values from the history object \n# Plot training & validation accuracy values\nplt.figure(figsize=(14, 5))\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='best')\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='best')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T16:04:45.314027Z","iopub.execute_input":"2024-11-14T16:04:45.314368Z","iopub.status.idle":"2024-11-14T16:04:46.031790Z","shell.execute_reply.started":"2024-11-14T16:04:45.314334Z","shell.execute_reply":"2024-11-14T16:04:46.030789Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Evaluate the model**","metadata":{}},{"cell_type":"code","source":"# # Evaluate the model\n# test_loss0, test_accuracy0 = model0.evaluate(x_test, y_test)\n# test_loss1, test_accuracy1 = model1.evaluate(x_test, y_test)\n# # test_loss2, test_accuracy2 = model2.evaluate(x_test, y_test)\n# # test_loss3, test_accuracy3 = model3.evaluate(x_test, y_test)\n# # test_loss4, test_accuracy4 = model4.evaluate(x_test, y_test)\n\n# print(f\"Test Loss without Batch Normalization: {test_loss0}\")\n# print(f\"Test Accuracy without Batch Normalization: {test_accuracy0}\")\n# print('')\n# print(f\"Test Loss with Batch Normalization: {test_loss1}\")\n# print(f\"Test Accuracy with Batch Normalization: {test_accuracy1}\")\n\n# # print(f\"Test Loss for dropout rate: 0.2: {test_loss2}\")\n# # print(f\"Test Accuracy for dropout rate: 0.2: {test_accuracy2}\")\n\n# # print(f\"Test Loss for dropout rate: 0.3: {test_loss3}\")\n# # print(f\"Test Accuracy for dropout rate: 0.3: {test_accuracy3}\")\n\n\n# # print(f\"Test Loss for dropout rate: 0.4: {test_loss4}\")\n# # print(f\"Test Accuracy for dropout rate: 0.4: {test_accuracy4}\")\n\n# #\n\n\ninput_ids_test = tokens_test['input_ids'].numpy()\nattention_mask_test = tokens_test['attention_mask'].numpy()\n\ntest_results = model.evaluate(\n    x={'input_ids': input_ids_test, 'attention_mask': attention_mask_test},\n    y=y_test,\n    batch_size=32,\n    verbose=1\n)\n\nprint(f\"Test Loss: {test_results[0]}\")\nprint(f\"Test Accuracy: {test_results[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T16:04:46.033102Z","iopub.execute_input":"2024-11-14T16:04:46.033531Z","iopub.status.idle":"2024-11-14T16:04:46.596091Z","shell.execute_reply.started":"2024-11-14T16:04:46.033469Z","shell.execute_reply":"2024-11-14T16:04:46.595103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T16:04:46.597565Z","iopub.execute_input":"2024-11-14T16:04:46.598016Z","iopub.status.idle":"2024-11-14T16:04:46.603174Z","shell.execute_reply.started":"2024-11-14T16:04:46.597966Z","shell.execute_reply":"2024-11-14T16:04:46.602242Z"}},"outputs":[],"execution_count":null}]}