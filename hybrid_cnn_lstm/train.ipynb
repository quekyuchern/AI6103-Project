{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport pandas as pd\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.datasets import fetch_20newsgroups\nimport torch\n\n# Automatically download missing NLTK resources\nnltk.download('punkt')\nnltk.download('stopwords')\n# Check CUDA availability and set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Custom print functions\ndef print_timer_info(message):\n    print(f\"[TIMER INFO] {message}\")\n\ndef print_output_data(message):\n    print(f\"[OUTPUT DATA] {message}\")\n\n\n# Load the dataset\nstart_time = time.time()\nprint_timer_info(\"Loading the 20 Newsgroups dataset...\")\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\ndf = pd.DataFrame({'Text': newsgroups.data, 'Category': newsgroups.target})\ndf['Category Name'] = df['Category'].apply(lambda x: newsgroups.target_names[x])\nprint_timer_info(f\"Time taken to load dataset: {time.time() - start_time:.2f} seconds\")\n\n# Pre-processing\nprint_timer_info(\"Starting pre-processing...\")\npreprocess_start_time = time.time()\n\ndf['Text'] = df['Text'].str.lower()  # Lowercasing\ndf['Text'] = df['Text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))  # Remove punctuation/special characters\ndf['Tokens'] = df['Text'].apply(word_tokenize)  # Tokenization\n\nstop_words = set(stopwords.words('english'))\ndf['Tokens'] = df['Tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])  # Stopwords removal\n\nstemmer = PorterStemmer()\ndf['Tokens'] = df['Tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])  # Stemming\n\nprint_timer_info(f\"Total time for pre-processing: {time.time() - preprocess_start_time:.2f} seconds\")\n\n# Move processed data to GPU if available (Example - converting text data to tensor)\nmax_token_length = max(df['Tokens'].apply(len))\nprint_output_data(f\"Maximum length of tokenized text: {max_token_length}\")\n","metadata":{"ExecuteTime":{"end_time":"2024-11-04T14:46:37.187204Z","start_time":"2024-11-04T14:46:07.103185Z"},"execution":{"iopub.status.busy":"2024-11-04T14:47:13.478071Z","iopub.execute_input":"2024-11-04T14:47:13.478401Z","iopub.status.idle":"2024-11-04T14:48:59.865716Z","shell.execute_reply.started":"2024-11-04T14:47:13.478365Z","shell.execute_reply":"2024-11-04T14:48:59.864605Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[TIMER INFO] Checking CUDA availability...\n[OUTPUT DATA] CUDA is available. Number of GPUs: 2\n[OUTPUT DATA] Device 0: Tesla T4\n[OUTPUT DATA] Device 1: Tesla T4\n[TIMER INFO] CUDA check completed. Using device: cuda\n[TIMER INFO] Loading the 20 Newsgroups dataset...\n[TIMER INFO] Time taken to load dataset: 12.74 seconds\n[TIMER INFO] Starting pre-processing...\n[TIMER INFO] Total time for pre-processing: 87.40 seconds\n[OUTPUT DATA] Maximum length of tokenized text: 6620\n","output_type":"stream"}]}]}